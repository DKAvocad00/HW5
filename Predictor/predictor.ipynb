{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Y PREDICTION MODEL"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ee16b735d1ea697d"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-08-26T17:40:46.958637614Z",
     "start_time": "2023-08-26T17:40:46.895997623Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "#creating model\n",
    "import time\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "#creating dataset\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "#warnings\n",
    "import warnings\n",
    "\n",
    "#default settings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "LENGTH_SEQUENCE = 10\n",
    "LEARNING_RATE = 0.1\n",
    "NUM_EPOCHS = 500\n",
    "BATCH_SIZE = 512\n",
    "INPUT_DIM = 10"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-26T17:40:47.020351421Z",
     "start_time": "2023-08-26T17:40:46.907204506Z"
    }
   },
   "id": "7d60b84fa6f5a3d6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data preprocessing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e7697cb1edd697a5"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# Generating Sequence \n",
    "def generateSequence(length = LENGTH_SEQUENCE):\n",
    "    x = torch.randint(0, 10, (length,))\n",
    "    y = torch.cat((x[0].unsqueeze(dim=0), torch.add(x[0], x[1:])))\n",
    "\n",
    "    for i in y:\n",
    "        if i >= 10:\n",
    "            i -= 10\n",
    "\n",
    "    return x.unsqueeze(dim=0), y.unsqueeze(dim=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-26T17:40:47.056765005Z",
     "start_time": "2023-08-26T17:40:46.915094700Z"
    }
   },
   "id": "20f61b9ffeb866f3"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "X,y = generateSequence()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-26T17:40:47.064743900Z",
     "start_time": "2023-08-26T17:40:46.961226751Z"
    }
   },
   "id": "b3db48a6694179bb"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# Creating dataset and make train test spliting\n",
    "\n",
    "def createDataset(number_sequences = 10000, length_sequence = LENGTH_SEQUENCE, test_size = 0.2, val_size = 0.1, batch_size = BATCH_SIZE):\n",
    "    x_train, y_train = generateSequence(length_sequence)\n",
    "    for _ in range(number_sequences - 1):\n",
    "        x, y = generateSequence(length_sequence)\n",
    "        x_train = torch.cat((x_train, x))\n",
    "        y_train = torch.cat((y_train, y))\n",
    "\n",
    "    x_test, y_test = generateSequence(length_sequence)\n",
    "    for _ in range(round(number_sequences * test_size) - 1):\n",
    "        x, y = generateSequence(length_sequence)\n",
    "        x_test = torch.cat((x_test, x))\n",
    "        y_test = torch.cat((y_test, y))\n",
    "\n",
    "    x_val, y_val = generateSequence(length_sequence)\n",
    "    for _ in range(round(number_sequences * val_size) - 1):\n",
    "        x, y = generateSequence(length_sequence)\n",
    "        x_val = torch.cat((x_val, x))\n",
    "        y_val = torch.cat((y_val, y))\n",
    "\n",
    "    train_dataset = TensorDataset(x_train, y_train)\n",
    "    test_dataset = TensorDataset(x_test, y_test)\n",
    "    val_dataset = TensorDataset(x_val, y_val)\n",
    "\n",
    "    train = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    return train, test, val"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-26T17:40:47.065202696Z",
     "start_time": "2023-08-26T17:40:46.961609838Z"
    }
   },
   "id": "9ee40aa2dfca20ab"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Creating model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "85a688b2a77146c6"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# Simple RNN model with LSTM,GRU or RNN cell\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, model, embed_dim, hidden_dim, layer_dim):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(INPUT_DIM, embed_dim)\n",
    "        self.model = model(embed_dim, hidden_dim, layer_dim, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_dim, INPUT_DIM)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embed = self.embed(sentence)\n",
    "        output, hidden = self.model(embed)\n",
    "        return self.linear(output)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-26T17:40:47.065470752Z",
     "start_time": "2023-08-26T17:40:46.961911698Z"
    }
   },
   "id": "46f337d237130481"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Creating training class"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3e90d4fb57af8ffe"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# Creating training class \n",
    "\n",
    "class Training:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.optimizer = torch.optim.SGD(self.model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "    def train(self, train, test):\n",
    "        for epoch in range(1, NUM_EPOCHS + 1):\n",
    "            train_loss, train_accuracy, iter_num = .0, .0, .0\n",
    "            start_epoch_time = time.time()\n",
    "            self.model.train()\n",
    "            for x, y in train:\n",
    "                x = x.to(device)\n",
    "                y = y.view(1, -1).squeeze().to(device)\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                out = self.model.forward(x).view(-1, INPUT_DIM)\n",
    "\n",
    "                loss = self.loss_fn(out, y)\n",
    "                train_loss += loss.item()\n",
    "\n",
    "                batch_accuracy = (out.argmax(dim=1) == y)\n",
    "                train_accuracy += batch_accuracy.sum().item() / batch_accuracy.shape[0]\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                iter_num += 1\n",
    "            if (epoch < 2) | (epoch % 50 == 0):\n",
    "                print(f\"Epoch: {epoch}, loss: {train_loss:.4f}, acc: \" f\"{train_accuracy / iter_num:.4f}\", end=\" | \")\n",
    "\n",
    "            test_loss, test_accuracy, iter_num = .0, .0, .0\n",
    "            self.model.eval().to(device)\n",
    "            for x, y in test:\n",
    "                x = x.to(device)\n",
    "                y = y.view(1, -1).squeeze().to(device)\n",
    "\n",
    "                out = self.model.forward(x).view(-1, INPUT_DIM)\n",
    "\n",
    "                loss = self.loss_fn(out, y)\n",
    "                test_loss += loss.item()\n",
    "\n",
    "                batch_accuracy = (out.argmax(dim=1) == y)\n",
    "                test_accuracy += batch_accuracy.sum().item() / batch_accuracy.shape[0]\n",
    "                iter_num += 1\n",
    "            if (epoch < 2) | (epoch % 50 == 0):\n",
    "                print(f\"test loss: {test_loss:.4f}, test acc: {test_accuracy / iter_num:.4f} | \" f\"{time.time() - start_epoch_time:.2f} sec.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-26T17:40:47.065687893Z",
     "start_time": "2023-08-26T17:40:46.962189741Z"
    }
   },
   "id": "e45a683e9b3e9e6c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "27f6667fadcebc42"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "train, test, val = createDataset()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-26T17:40:48.889071988Z",
     "start_time": "2023-08-26T17:40:46.962532180Z"
    }
   },
   "id": "15f3e68de4e236c1"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "models = {\n",
    "        \"RNN\": [nn.RNN, 32, 128, 5],\n",
    "        \"LSTM\": [nn.LSTM, 32, 64, 1],\n",
    "        \"GRU\": [nn.GRU, 32, 64, 1]\n",
    "        }\n",
    "model_RNN = Model(*models[\"RNN\"]).to(device)\n",
    "model_GRU = Model(*models[\"GRU\"]).to(device)\n",
    "model_LSTM = Model(*models[\"LSTM\"]).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-26T17:40:48.938136032Z",
     "start_time": "2023-08-26T17:40:48.891274127Z"
    }
   },
   "id": "a659632a7090da25"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, loss: 46.0642, acc: 0.0980 | test loss: 9.2085, test acc: 0.0979 | 0.46 sec.\n",
      "Epoch: 50, loss: 39.7972, acc: 0.2340 | test loss: 7.9934, test acc: 0.2277 | 0.45 sec.\n",
      "Epoch: 100, loss: 16.4282, acc: 0.5483 | test loss: 3.4211, test acc: 0.5341 | 0.41 sec.\n",
      "Epoch: 150, loss: 0.1364, acc: 1.0000 | test loss: 0.0273, test acc: 1.0000 | 0.43 sec.\n",
      "Epoch: 200, loss: 0.0512, acc: 1.0000 | test loss: 0.0103, test acc: 1.0000 | 0.23 sec.\n",
      "Epoch: 250, loss: 0.0308, acc: 1.0000 | test loss: 0.0063, test acc: 1.0000 | 0.24 sec.\n",
      "Epoch: 300, loss: 0.0218, acc: 1.0000 | test loss: 0.0044, test acc: 1.0000 | 0.21 sec.\n",
      "Epoch: 350, loss: 0.0168, acc: 1.0000 | test loss: 0.0034, test acc: 1.0000 | 0.28 sec.\n",
      "Epoch: 400, loss: 0.0136, acc: 1.0000 | test loss: 0.0028, test acc: 1.0000 | 0.28 sec.\n",
      "Epoch: 450, loss: 0.0114, acc: 1.0000 | test loss: 0.0023, test acc: 1.0000 | 0.23 sec.\n",
      "Epoch: 500, loss: 0.0098, acc: 1.0000 | test loss: 0.0020, test acc: 1.0000 | 0.23 sec.\n"
     ]
    }
   ],
   "source": [
    "# Training RNN with rnn cell\n",
    "\n",
    "training_RNN = Training(model_RNN)\n",
    "training_RNN.train(train, test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-26T17:43:19.332749258Z",
     "start_time": "2023-08-26T17:40:48.933003296Z"
    }
   },
   "id": "82c0aff0ff3d0c12"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, loss: 46.0690, acc: 0.1308 | test loss: 9.1985, test acc: 0.1266 | 0.14 sec.\n",
      "Epoch: 50, loss: 45.1465, acc: 0.1933 | test loss: 9.0574, test acc: 0.1841 | 0.14 sec.\n",
      "Epoch: 100, loss: 43.5866, acc: 0.1979 | test loss: 8.7343, test acc: 0.1896 | 0.13 sec.\n",
      "Epoch: 150, loss: 39.6761, acc: 0.2556 | test loss: 7.9394, test acc: 0.2501 | 0.13 sec.\n",
      "Epoch: 200, loss: 15.1622, acc: 0.8953 | test loss: 2.9665, test acc: 0.9001 | 0.11 sec.\n",
      "Epoch: 250, loss: 1.5494, acc: 0.9999 | test loss: 0.3111, test acc: 0.9999 | 0.13 sec.\n",
      "Epoch: 300, loss: 0.6326, acc: 1.0000 | test loss: 0.1278, test acc: 0.9999 | 0.12 sec.\n",
      "Epoch: 350, loss: 0.3789, acc: 1.0000 | test loss: 0.0766, test acc: 1.0000 | 0.17 sec.\n",
      "Epoch: 400, loss: 0.2651, acc: 1.0000 | test loss: 0.0536, test acc: 1.0000 | 0.13 sec.\n",
      "Epoch: 450, loss: 0.2022, acc: 1.0000 | test loss: 0.0409, test acc: 1.0000 | 0.12 sec.\n",
      "Epoch: 500, loss: 0.1626, acc: 1.0000 | test loss: 0.0328, test acc: 1.0000 | 0.11 sec.\n"
     ]
    }
   ],
   "source": [
    "# Training RNN with gru cell\n",
    "\n",
    "training_GRU = Training(model_GRU)\n",
    "training_GRU.train(train, test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-26T17:44:26.834034170Z",
     "start_time": "2023-08-26T17:43:19.334253527Z"
    }
   },
   "id": "38b7380375355ea1"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, loss: 46.0786, acc: 0.1023 | test loss: 9.2136, test acc: 0.0984 | 0.13 sec.\n",
      "Epoch: 50, loss: 45.2861, acc: 0.1928 | test loss: 9.0751, test acc: 0.1845 | 0.14 sec.\n",
      "Epoch: 100, loss: 44.5541, acc: 0.1944 | test loss: 8.9298, test acc: 0.1868 | 0.14 sec.\n",
      "Epoch: 150, loss: 38.7255, acc: 0.2973 | test loss: 7.7640, test acc: 0.2894 | 0.16 sec.\n",
      "Epoch: 200, loss: 24.0121, acc: 0.6104 | test loss: 4.8069, test acc: 0.6124 | 0.12 sec.\n",
      "Epoch: 250, loss: 3.5890, acc: 0.9989 | test loss: 0.7207, test acc: 0.9987 | 0.13 sec.\n",
      "Epoch: 300, loss: 1.0765, acc: 1.0000 | test loss: 0.2194, test acc: 0.9999 | 0.19 sec.\n",
      "Epoch: 350, loss: 0.5496, acc: 1.0000 | test loss: 0.1134, test acc: 1.0000 | 0.13 sec.\n",
      "Epoch: 400, loss: 0.3534, acc: 1.0000 | test loss: 0.0734, test acc: 1.0000 | 0.13 sec.\n",
      "Epoch: 450, loss: 0.2554, acc: 1.0000 | test loss: 0.0534, test acc: 1.0000 | 0.13 sec.\n",
      "Epoch: 500, loss: 0.1986, acc: 1.0000 | test loss: 0.0417, test acc: 1.0000 | 0.13 sec.\n"
     ]
    }
   ],
   "source": [
    "# Training RNN with LSTM cell\n",
    "\n",
    "training_LSTM = Training(model_LSTM)\n",
    "training_LSTM.train(train, test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-26T17:45:35.994972399Z",
     "start_time": "2023-08-26T17:44:26.835103669Z"
    }
   },
   "id": "b3b255a8adce7bdb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Calculating score"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "456c6115b58c9df0"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "# Calculating accuracy score on validation dataset\n",
    "\n",
    "def calculatingScore(model):\n",
    "    val_loss, val_accuracy, iter_num = .0, .0, 0\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    model.eval()\n",
    "    \n",
    "    for x, y in val:\n",
    "      x = x.to(device)\n",
    "      y = y.view(1, -1).squeeze().to(device)\n",
    "    \n",
    "      out = model.forward(x).view(-1, INPUT_DIM)\n",
    "    \n",
    "      loss = loss_fn(out, y)\n",
    "      val_loss += loss.item()\n",
    "    \n",
    "      batch_accuracy = (out.argmax(dim=1) == y)\n",
    "      val_accuracy += batch_accuracy.sum().item() / batch_accuracy.shape[0]\n",
    "      iter_num += 1\n",
    "    \n",
    "    print(f\"val loss: {val_loss:.4f} | val acc: {val_accuracy / iter_num:.4f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-26T17:45:35.995580658Z",
     "start_time": "2023-08-26T17:45:35.992011566Z"
    }
   },
   "id": "2229ef20c806efa2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Results"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "10b46b3db0bd1f6f"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN model: \n",
      "val loss: 0.0010 | val acc: 1.0000\n",
      "GRU model: \n",
      "val loss: 0.0170 | val acc: 1.0000\n",
      "LSTM model: \n",
      "val loss: 0.0205 | val acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "print(\"RNN model: \")\n",
    "calculatingScore(model_RNN)\n",
    "print(\"GRU model: \")\n",
    "calculatingScore(model_GRU)\n",
    "print(\"LSTM model: \")\n",
    "calculatingScore(model_LSTM)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-26T17:45:36.042647937Z",
     "start_time": "2023-08-26T17:45:35.997252897Z"
    }
   },
   "id": "c542acc96e09f61f"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-26T17:45:36.048968754Z",
     "start_time": "2023-08-26T17:45:36.044457487Z"
    }
   },
   "id": "76135b10549d5aaf"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
